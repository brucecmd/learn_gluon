{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AlexNet.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/brucecmd/learn_gluon/blob/master/AlexNet.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "-7zbQrpe2S7s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from mxnet.gluon import nn\n",
        "import mxnet as mx\n",
        "from mxnet.gluon import loss as gloss\n",
        "from time import time\n",
        "from mxnet.gluon import data as gdata\n",
        "from mxnet import gluon, init, autograd, nd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5vpniM6Q30EJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "###LeNet\n",
        "#net = nn.Sequential()\n",
        "#net.add(\n",
        "#nn.Conv2D(channels=6, kernel_size=5, activation='sigmoid'),\n",
        "#nn.MaxPool2D(pool_size=2, strides=2),\n",
        "#nn.Conv2D(channels=16, kernel_size=5, activation='sigmoid'),\n",
        "#nn.MaxPool2D(pool_size=2, strides=2),\n",
        "#nn.Dense(120, activation='sigmoid'),\n",
        "#nn.Dense(84, activation='sigmoid'),\n",
        "#nn.Dense(10)\n",
        "#)\n",
        "\n",
        "# AlexNet\n",
        "net = nn.Sequential()\n",
        "net.add(nn.Conv2D(96, kernel_size=11, strides=4, activation='relu'))\n",
        "net.add(nn.MaxPool2D(pool_size=3,strides=2))\n",
        "\n",
        "net.add(nn.Conv2D(channels=256, kernel_size=5, padding=2, activation='relu'))\n",
        "net.add(nn.MaxPool2D(pool_size=3, strides=2))\n",
        "\n",
        "net.add(nn.Conv2D(channels=384, kernel_size=3, padding=1, activation='relu'))\n",
        "net.add(nn.Conv2D(channels=384, kernel_size=3, padding=1, activation='relu'))\n",
        "net.add(nn.Conv2D(channels=256, kernel_size=3, padding=1, activation='relu'))\n",
        "net.add(nn.MaxPool2D(pool_size=3, strides=2))\n",
        "\n",
        "#net.add(nn.Dense(4096, activation='relu'))\n",
        "#net.add(nn.Dropout(0.5))\n",
        "\n",
        "#net.add(nn.Dense(4096, activation='relu'))\n",
        "#net.add(nn.Dropout(0.5))\n",
        "\n",
        "net.add(nn.Dense(10))\n",
        "\n",
        "net.initialize(init.Xavier()) # 要注意的是，这里的sigma选太小的话，训不出结果来nn\n",
        "#print(net)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RDoZHxuXP4-V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "8e399023-a586-4e77-da91-98478a9b0c3d"
      },
      "cell_type": "code",
      "source": [
        "X = nd.random.uniform(shape=(1, 1, 224, 224))\n",
        "for layer in net:\n",
        "    X = layer(X)\n",
        "    print(layer.name, 'output shape:\\t', X.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv5 output shape:\t (1, 96, 54, 54)\n",
            "pool3 output shape:\t (1, 96, 26, 26)\n",
            "conv6 output shape:\t (1, 256, 26, 26)\n",
            "pool4 output shape:\t (1, 256, 12, 12)\n",
            "conv7 output shape:\t (1, 384, 12, 12)\n",
            "conv8 output shape:\t (1, 384, 12, 12)\n",
            "conv9 output shape:\t (1, 256, 12, 12)\n",
            "pool5 output shape:\t (1, 256, 5, 5)\n",
            "dense1 output shape:\t (1, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tUClywqX5Izn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mnist_train = gdata.vision.FashionMNIST(train=True)\n",
        "mnist_test = gdata.vision.FashionMNIST(train=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "970ssuD_5b_H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 256\n",
        "transformer = []\n",
        "transformer += [gdata.vision.transforms.Resize(224)] # 要先resize再totensor\n",
        "transformer += [gdata.vision.transforms.ToTensor()]\n",
        "transformer = gdata.vision.transforms.Compose(transformer)\n",
        "train_iter = gdata.DataLoader(mnist_train.transform_first(transformer), batch_size, shuffle=True)\n",
        "test_iter = gdata.DataLoader(mnist_test.transform_first(transformer), batch_size, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jrbl4MvT6MEv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def accuracy(y_hat, y):\n",
        "    return (y_hat.argmax(axis=1)==y.astype('float32')).mean().asscalar()\n",
        "\n",
        "  \n",
        "def evaluate_accuracy(data_iter, net):\n",
        "    acc = nd.array([0])\n",
        "    for x, y in data_iter:\n",
        "        acc += accuracy(net(x), y)\n",
        "    return acc.asscalar() / len(data_iter)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L_zNMJMy6OuC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "loss_func = gloss.SoftmaxCrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DBwU_dq5L63U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate':0.1})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iAiwPyUu7wDu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "batch_size = 256\n",
        "\n",
        "for i in range(epochs):\n",
        "    for data, label in train_iter:\n",
        "        with autograd.record():\n",
        "            y_hat = net(data)\n",
        "            l = loss_func(y_hat, label)\n",
        "        l.backward()\n",
        "        trainer.step(batch_size)\n",
        "    train_acc = evaluate_accuracy(train_iter, net)\n",
        "    test_acc = evaluate_accuracy(test_iter, net)\n",
        "    print('epoch[%d], train acc[%f], test acc[%f]'%(i, train_acc, test_acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jbgz-GONGxJ5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}