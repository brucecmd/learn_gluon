{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dropout_raw.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/brucecmd/learn_gluon/blob/master/dropout_raw.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "q6SCeHkmJ1Ax",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from mxnet import autograd, nd\n",
        "from mxnet.gluon import loss as gloss\n",
        "from mxnet.gluon import data as gdata\n",
        "from mxnet import gluon"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5R1AWKUWLfju",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# define dropout function\n",
        "def dropout(x, drop_prob):\n",
        "    assert drop_prob>=0 and drop_prob<=1\n",
        "    keep_prob = 1 - drop_prob\n",
        "    if keep_prob ==0:\n",
        "        return x.zeros_like()\n",
        "    mask = nd.random_uniform(0,1,shape=(x.shape)) < keep_prob\n",
        "    return x * mask / keep_prob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dXhGH36jMHas",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "50143a0b-0ddb-4558-e588-df8c643c8f2c"
      },
      "cell_type": "code",
      "source": [
        "x = nd.arange(20).reshape((4,5))\n",
        "print(x)\n",
        "print(dropout(x,0.5))"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[[ 0.  1.  2.  3.  4.]\n",
            " [ 5.  6.  7.  8.  9.]\n",
            " [10. 11. 12. 13. 14.]\n",
            " [15. 16. 17. 18. 19.]]\n",
            "<NDArray 4x5 @cpu(0)>\n",
            "\n",
            "[[ 0.  0.  0.  6.  0.]\n",
            " [10.  0.  0.  0. 18.]\n",
            " [20. 22. 24. 26. 28.]\n",
            " [ 0.  0. 34.  0. 38.]]\n",
            "<NDArray 4x5 @cpu(0)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zomD2y9_MmJ2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# defien params\n",
        "num_inputs = 784\n",
        "num_outputs = 10\n",
        "num_hidden1 = 256\n",
        "num_hidden2 = 256\n",
        "\n",
        "w1 = nd.random_normal(0,0.01,shape=(num_inputs,num_hidden1))\n",
        "b1 = nd.zeros((num_hidden1,))\n",
        "w2 = nd.random_normal(0,0.01,shape=(num_hidden1, num_hidden2))\n",
        "b2 = nd.zeros((num_hidden2,))\n",
        "w3 = nd.random_normal(0,0.01,shape=(num_hidden2,num_outputs))\n",
        "b3 = nd.zeros((num_outputs,))\n",
        "\n",
        "params = [w1,w2,w3,b1,b2,b3]\n",
        "for p in params:\n",
        "    p.attach_grad()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wQhxnR5KNprJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load data\n",
        "mnist_train = gdata.vision.FashionMNIST(train=True)\n",
        "mnist_test = gdata.vision.FashionMNIST(train=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c0z4CSpVONjx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# prepare data iter\n",
        "batch_size = 256\n",
        "transformer = gdata.vision.transforms.ToTensor()\n",
        "train_iter = gdata.DataLoader(mnist_train.transform_first(transformer), batch_size, shuffle=True)\n",
        "test_iter = gdata.DataLoader(mnist_test.transform_first(transformer), batch_size, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gTKgobxgOh1M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# define net\n",
        "dropout_prob1 = 0.5\n",
        "dropout_prob2 = 0.2\n",
        "\n",
        "def net(x):\n",
        "    x = x.reshape((-1, num_inputs))\n",
        "    h1 = nd.relu(nd.dot(x,w1) + b1)\n",
        "    if autograd.is_training():\n",
        "        h1 = dropout(h1,dropout_prob1)\n",
        "    h2 = nd.relu(nd.dot(h1,w2) + b2)\n",
        "    if autograd.is_training():\n",
        "        h2 = dropout(h2, dropout_prob2)\n",
        "    return nd.dot(h2,w3) + b3\n",
        "def net2(x):\n",
        "    x = x.reshape((-1, num_inputs))\n",
        "    h1 = nd.relu(nd.dot(x,w1) + b1)\n",
        "    h2 = nd.relu(nd.dot(h1,w2) + b2)\n",
        "    return nd.dot(h2,w3) + b3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5cffgJtCfJVN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sgd(params, batch_size, lr):\n",
        "    for p in params:\n",
        "        p[:] -= p.grad * lr / batch_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h6Des9fHgalS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "loss_func = gloss.SoftmaxCrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rND6hoFEgenS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def accuracy(y_hat, y):\n",
        "    return (y_hat.argmax(axis=1)==y.astype('float32')).mean().asscalar()\n",
        "  \n",
        "def estimate_accuracy(data_iter, net):\n",
        "    total_acc = 0\n",
        "    for data, label in data_iter:\n",
        "        y_hat = net(data)\n",
        "        acc = accuracy(y_hat, label)\n",
        "        total_acc += acc\n",
        "    return total_acc / len(data_iter)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "POk_ewbbuj6i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "batch_size=256\n",
        "lr=0.01\n",
        "dropout_prob1=0.2\n",
        "dropout_prob2=0.5\n",
        "\n",
        "epoch[0], train acc[0.119310], test acc[0.116016]\n",
        "\n",
        "epoch[1], train acc[0.146604], test acc[0.147168]\n",
        "\n",
        "epoch[2], train acc[0.112417], test acc[0.115918]\n",
        "\n",
        "epoch[3], train acc[0.180846], test acc[0.185840]\n",
        "\n",
        "epoch[4], train acc[0.409081], test acc[0.409668]\n",
        "\n",
        "epoch[5], train acc[0.455158], test acc[0.452734]\n",
        "\n",
        "epoch[6], train acc[0.513725], test acc[0.504199]\n",
        "\n",
        "epoch[7], train acc[0.589711], test acc[0.582129]\n",
        "\n",
        "epoch[8], train acc[0.630059], test acc[0.627539]\n",
        "\n",
        "epoch[9], train acc[0.661115], test acc[0.667676]\n",
        "\n",
        "-==========================================\n",
        "\n",
        "batch_size=256\n",
        "lr=0.001\n",
        "\n",
        "epoch[0], train acc[0.094753], test acc[0.096777]\n",
        "\n",
        "epoch[1], train acc[0.108455], test acc[0.107813]\n",
        "\n",
        "epoch[2], train acc[0.122025], test acc[0.120801]\n",
        "\n",
        "epoch[3], train acc[0.136447], test acc[0.133594]\n",
        "\n",
        "epoch[4], train acc[0.159403], test acc[0.157715]\n",
        "\n",
        "epoch[5], train acc[0.186824], test acc[0.190625]\n",
        "\n",
        "epoch[6], train acc[0.214484], test acc[0.212109]\n",
        "\n",
        "epoch[7], train acc[0.240852], test acc[0.242773]\n",
        "\n",
        "epoch[8], train acc[0.267010], test acc[0.269727]\n",
        "\n",
        "epoch[9], train acc[0.290924], test acc[0.292480]\n",
        "\n",
        "lr更小了，但是看loss，比lr大的时候更稳定了，loss没有出现一下变大，一下又变小的情况。后面加大epoch，观察一下loss最小能够到什么程度。\n",
        "-==========================================\n",
        "\n",
        "batch_size=256\n",
        "lr=0.001\n",
        "epochs=20\n",
        "\n",
        "epoch[0], train acc[0.090841], test acc[0.085742]\n",
        "\n",
        "epoch[1], train acc[0.098482], test acc[0.097754]\n",
        "\n",
        "epoch[2], train acc[0.106992], test acc[0.105371]\n",
        "\n",
        "epoch[3], train acc[0.117404], test acc[0.114355]\n",
        "\n",
        "epoch[4], train acc[0.128801], test acc[0.122949]\n",
        "\n",
        "epoch[5], train acc[0.142858], test acc[0.141309]\n",
        "\n",
        "epoch[6], train acc[0.156483], test acc[0.153516]\n",
        "\n",
        "epoch[7], train acc[0.168706], test acc[0.165527]\n",
        "\n",
        "epoch[8], train acc[0.180563], test acc[0.179199]\n",
        "\n",
        "epoch[9], train acc[0.191933], test acc[0.191309]\n",
        "\n",
        "epoch[10], train acc[0.200449], test acc[0.202344]\n",
        "\n",
        "epoch[11], train acc[0.206150], test acc[0.205469]\n",
        "\n",
        "epoch[12], train acc[0.205884], test acc[0.208496]\n",
        "\n",
        "epoch[13], train acc[0.197185], test acc[0.201953]\n",
        "\n",
        "epoch[14], train acc[0.182968], test acc[0.181055]\n",
        "\n",
        "epoch[15], train acc[0.166888], test acc[0.165820]\n",
        "\n",
        "epoch[16], train acc[0.151313], test acc[0.147168]\n",
        "\n",
        "epoch[17], train acc[0.139943], test acc[0.140137]\n",
        "\n",
        "epoch[18], train acc[0.132430], test acc[0.132324]\n",
        "\n",
        "epoch[19], train acc[0.126435], test acc[0.122949]\n",
        "\n",
        "结果打脸了，这一版的参数下，结果也出现了波动。后面看一下lr=0.01的时候，loss最好情况能到达什么样的程度。\n",
        "\n",
        "-==========================================\n",
        "\n",
        "batch_size=256\n",
        "lr=0.01\n",
        "epochs=50\n",
        "\n",
        "大概 train_loss 和 test_loss都达到了0.83左右。\n",
        "调大lr试试。\n",
        "\n",
        "-===========================================\n",
        "\n",
        "batch_size=256\n",
        "lr=0.1\n",
        "epoch=20\n",
        "\n",
        "epoch[0], train acc[0.608959], test acc[0.602930]\n",
        "\n",
        "epoch[1], train acc[0.743146], test acc[0.742090]\n",
        "\n",
        "epoch[2], train acc[0.787467], test acc[0.779785]\n",
        "\n",
        "epoch[3], train acc[0.816162], test acc[0.810547]\n",
        "\n",
        "epoch[4], train acc[0.823482], test acc[0.826172]\n",
        "\n",
        "epoch[5], train acc[0.835699], test acc[0.830371]\n",
        "\n",
        "epoch[6], train acc[0.842537], test acc[0.838867]\n",
        "\n",
        "epoch[7], train acc[0.846947], test acc[0.843848]\n",
        "\n",
        "epoch[8], train acc[0.856294], test acc[0.851855]\n",
        "\n",
        "epoch[9], train acc[0.865187], test acc[0.859082]\n",
        "\n",
        "epoch[10], train acc[0.867819], test acc[0.867676]\n",
        "\n",
        "epoch[11], train acc[0.871022], test acc[0.864551]\n",
        "\n",
        "epoch[12], train acc[0.873460], test acc[0.868457]\n",
        "\n",
        "epoch[13], train acc[0.879000], test acc[0.870605]\n",
        "\n",
        "epoch[14], train acc[0.880297], test acc[0.870801]\n",
        "\n",
        "epoch[15], train acc[0.881189], test acc[0.871973]\n",
        "\n",
        "epoch[16], train acc[0.886553], test acc[0.877637]\n",
        "\n",
        "epoch[17], train acc[0.885145], test acc[0.875586]\n",
        "\n",
        "epoch[18], train acc[0.885295], test acc[0.876660]\n",
        "\n",
        "epoch[19], train acc[0.890647], test acc[0.874414]\n",
        "\n",
        "看起来lr=0.1表现好多了，收敛的快了很多。后面加上dropout，看看会表现如何。\n",
        "\n",
        "-=============================================\n",
        "\n",
        "batch_size=256\n",
        "lr=0.1\n",
        "nodropout\n",
        "\n",
        "epoch[0], train acc[0.628341], test acc[0.627441]\n",
        "\n",
        "epoch[1], train acc[0.745191], test acc[0.737793]\n",
        "\n",
        "epoch[2], train acc[0.801889], test acc[0.796875]\n",
        "\n",
        "epoch[3], train acc[0.811647], test acc[0.811133]\n",
        "\n",
        "epoch[4], train acc[0.831394], test acc[0.826270]\n",
        "\n",
        "epoch[5], train acc[0.842919], test acc[0.837793]\n",
        "\n",
        "epoch[6], train acc[0.848177], test acc[0.848047]\n",
        "\n",
        "epoch[7], train acc[0.851446], test acc[0.850195]\n",
        "\n",
        "epoch[8], train acc[0.859491], test acc[0.849805]\n",
        "\n",
        "epoch[9], train acc[0.861807], test acc[0.860352]\n",
        "\n",
        "epoch[10], train acc[0.867437], test acc[0.860645]\n",
        "\n",
        "epoch[11], train acc[0.868484], test acc[0.861426]\n",
        "\n",
        "epoch[12], train acc[0.875211], test acc[0.871875]\n",
        "\n",
        "epoch[13], train acc[0.874014], test acc[0.868359]\n",
        "\n",
        "epoch[14], train acc[0.881560], test acc[0.874219]\n",
        "\n",
        "epoch[15], train acc[0.880918], test acc[0.872559]\n",
        "\n",
        "epoch[16], train acc[0.884092], test acc[0.874219]\n",
        "\n",
        "epoch[17], train acc[0.887129], test acc[0.878320]\n",
        "\n",
        "epoch[18], train acc[0.887395], test acc[0.873145]\n",
        "\n",
        "epoch[19], train acc[0.885062], test acc[0.878125]\n",
        "\n",
        "\n",
        "-=========================================\n",
        "\n",
        "batch_size=256\n",
        "lr=0.1\n",
        "dropout_prob1=0.5\n",
        "dropout_prob2=0.2\n",
        "\n",
        "epoch[0], train acc[0.606028], test acc[0.601172]\n",
        "\n",
        "epoch[1], train acc[0.737932], test acc[0.735547]\n",
        "\n",
        "epoch[2], train acc[0.779959], test acc[0.780566]\n",
        "\n",
        "epoch[3], train acc[0.817797], test acc[0.816406]\n",
        "\n",
        "epoch[4], train acc[0.833505], test acc[0.831445]\n",
        "\n",
        "epoch[5], train acc[0.834713], test acc[0.834180]\n",
        "\n",
        "epoch[6], train acc[0.850648], test acc[0.851953]\n",
        "\n",
        "epoch[7], train acc[0.856056], test acc[0.855371]\n",
        "\n",
        "epoch[8], train acc[0.856549], test acc[0.849805]\n",
        "\n",
        "epoch[9], train acc[0.864583], test acc[0.862500]\n",
        "\n",
        "epoch[10], train acc[0.868163], test acc[0.865723]\n",
        "\n",
        "epoch[11], train acc[0.866872], test acc[0.863770]\n",
        "\n",
        "epoch[12], train acc[0.875244], test acc[0.870996]\n",
        "\n",
        "epoch[13], train acc[0.875017], test acc[0.871680]\n",
        "\n",
        "epoch[14], train acc[0.878529], test acc[0.872949]\n",
        "\n",
        "epoch[15], train acc[0.881682], test acc[0.875488]\n",
        "\n",
        "epoch[16], train acc[0.875659], test acc[0.862207]\n",
        "\n",
        "epoch[17], train acc[0.885888], test acc[0.875977]\n",
        "\n",
        "epoch[18], train acc[0.887705], test acc[0.877148]\n",
        "\n",
        "epoch[19], train acc[0.885289], test acc[0.874512]\n",
        "\n",
        "看起来，加了dropout_prob也没什么改善，之后把模型变复杂一些，看看dropout的作用吧。\n"
      ]
    },
    {
      "metadata": {
        "id": "VMuFIKo4iFfU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "e64b0995-5164-4d2f-dc3c-a79b873d7195"
      },
      "cell_type": "code",
      "source": [
        "epochs = 20\n",
        "lr = 0.1\n",
        "batch_size = 256\n",
        "for i in range(epochs):\n",
        "    for data, label in train_iter:\n",
        "        with autograd.record():\n",
        "            y_hat = net(data)\n",
        "            l = loss_func(y_hat, label)\n",
        "        l.backward()\n",
        "        sgd(params, batch_size, lr)\n",
        "    train_acc = estimate_accuracy(train_iter, net)\n",
        "    test_acc = estimate_accuracy(test_iter, net)\n",
        "    print('epoch[%d], train acc[%f], test acc[%f]'%(i, train_acc, test_acc))"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch[0], train acc[0.606028], test acc[0.601172]\n",
            "epoch[1], train acc[0.737932], test acc[0.735547]\n",
            "epoch[2], train acc[0.779959], test acc[0.780566]\n",
            "epoch[3], train acc[0.817797], test acc[0.816406]\n",
            "epoch[4], train acc[0.833505], test acc[0.831445]\n",
            "epoch[5], train acc[0.834713], test acc[0.834180]\n",
            "epoch[6], train acc[0.850648], test acc[0.851953]\n",
            "epoch[7], train acc[0.856056], test acc[0.855371]\n",
            "epoch[8], train acc[0.856549], test acc[0.849805]\n",
            "epoch[9], train acc[0.864583], test acc[0.862500]\n",
            "epoch[10], train acc[0.868163], test acc[0.865723]\n",
            "epoch[11], train acc[0.866872], test acc[0.863770]\n",
            "epoch[12], train acc[0.875244], test acc[0.870996]\n",
            "epoch[13], train acc[0.875017], test acc[0.871680]\n",
            "epoch[14], train acc[0.878529], test acc[0.872949]\n",
            "epoch[15], train acc[0.881682], test acc[0.875488]\n",
            "epoch[16], train acc[0.875659], test acc[0.862207]\n",
            "epoch[17], train acc[0.885888], test acc[0.875977]\n",
            "epoch[18], train acc[0.887705], test acc[0.877148]\n",
            "epoch[19], train acc[0.885289], test acc[0.874512]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1ngrg9g0thZJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}